{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f9218e",
   "metadata": {},
   "source": [
    "# Tutorial #5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2ac68",
   "metadata": {},
   "source": [
    "1. Write a function `my_lin_regression(f, x, y)` where `f` is a list containing function objects to basis functions, and `x` and `y` are arrays containing noisy data. Assume that `x` and `y` are the same size. Let an estimation function for the data contained in `x` and `y` be defined as $\\hat{y}(x) = \\beta(1) · f_1(x) + \\beta(2) · f_2(x) + ··· + \\beta(n) · f_n(x) + \\beta(n+1)$, where `n` is the length of `f`. Your function should compute *beta* according to the least squares regression formula.\\\n",
    "Test Case: Note that your solution may vary by a little bit, depending on the random numbers generated.\n",
    "```\n",
    "    x = np.linspace(0, 2*np.pi, 1000)\n",
    "    y = 3*np.sin(x) - 2*np.cos(x) + np.random.random(len(x))\n",
    "    f = [np.sin, np.cos]\n",
    "    beta = my_lin_regression(f, x, y)\n",
    "    plt.figure(figsize = (10,8))\n",
    "    plt.plot(x,y,\"b.\", label = \"data\")\n",
    "    plt.plot(x, beta[0]*f[0](x)+beta[1]*f[1](x)+beta[2], \"r\", label=\"regression\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Least Square Regression Example\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def my_lin_regression(f, x, y):\n",
    "    \n",
    "    A = np.array([fi(x) for fi in f]).T\n",
    "    ones = np.ones((len(x), 1))\n",
    "    A = np.append(A, ones, axis=1)\n",
    "    \n",
    "    # least squares regression formula\n",
    "    At_Ainv = np.linalg.inv(np.dot(A.T, A))\n",
    "    At_Y = np.dot(A.T, y)\n",
    "    beta = np.dot(At_Ainv, At_Y)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "# Test case\n",
    "x = np.linspace(0, 2*np.pi, 1000)\n",
    "y = 3*np.sin(x) - 2*np.cos(x) + np.random.random(len(x))\n",
    "f = [np.sin, np.cos]\n",
    "beta = my_lin_regression(f, x, y)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(x, y, \"b.\", label=\"data\")\n",
    "plt.plot(x, beta[0]*f[0](x) + beta[1]*f[1](x) + beta[2], \"r\", label=\"regression\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Least Square Regression Example\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe67dd5",
   "metadata": {},
   "source": [
    "2. Write a function `my_exp_regression(x,y)` where `x` and `y` are arrays of the same size. Let an estimation function for the data contained in `x` and `y` be defined as $\\hat{y}(x) = \\alpha\\exp(\\beta x)$. Your function should compute $\\alpha$ and $\\beta$ to solve the least squares regression formula.\n",
    "Test Cases: Note that your solution may vary slightly from the test case, depending on the random\n",
    "numbers generated.\n",
    "```\n",
    "    x = np.linspace(0, 1, 1000)\n",
    "    y = 2*np.exp(-0.5*x) + 0.25*np.random.random(len(x))\n",
    "    alpha, beta = my_exp_regression(x, y)\n",
    "    plt.figure(figsize = (10,8))\n",
    "    plt.plot(x,y,\"b.\", label = \"data\")\n",
    "    plt.plot(x, alpha*np.exp(beta*x), \"r\", label=\"regression\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Least Square Regression on Exponential Model\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_exp_regression(x, y):\n",
    "    A = np.array([np.ones(len(x)),x]).T\n",
    "    \n",
    "    # least squares regression formula\n",
    "    At_Ainv = np.linalg.inv(np.dot(A.T, A))\n",
    "    At_Y = np.dot(A.T, np.log(y))\n",
    "    ln_alpha, beta = np.dot(At_Ainv, At_Y)\n",
    "    alpha = np.exp(ln_alpha)\n",
    "    \n",
    "    return alpha, beta\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = 2*np.exp(-0.5*x) + 0.25*np.random.random(len(x))\n",
    "\n",
    "alpha, beta = my_exp_regression(x, y)\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(x,y,\"b.\", label = \"data\")\n",
    "plt.plot(x, alpha*np.exp(beta*x), \"r\", label=\"regression\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Least Square Regression on Exponential Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a170f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
